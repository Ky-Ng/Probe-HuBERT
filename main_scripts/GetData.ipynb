{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting HuBERT Hidden Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from transformers import HubertForCTC, Wav2Vec2Processor\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict \n",
    "\n",
    "# Custom Helper Libraries\n",
    "from helper_scripts.TenseLax import TenseLax\n",
    "from helper_scripts.AudioProcessing import AudioProcessing\n",
    "from helper_scripts.Constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "```\n",
    "let n = number of samples of audio files\n",
    "let s = number of segments/phonemes to be segmented\n",
    "let k = number of encoders in LLM\n",
    "let l[i] = number of speech vectors per input sequence\n",
    "```\n",
    "\n",
    "1) Select n=200 samples of audio files from a specific subset of dialects from `TIMIT`\n",
    "2) Create the output `hidden_states`\n",
    "    - s entries\n",
    "    - each entry is a size k=25 array \n",
    "    - each array index is a numpy array representing `l[i]` speech vectors--where each speech vector is of size 1024\n",
    "3) Load in each of the n samples using `librosa`\n",
    "4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import Audio Files\n",
    "- Extract 200 path's to audio samples to save computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 4969 speech samples\n",
      "Succesfully randomly sampled 200 speech samples\n"
     ]
    }
   ],
   "source": [
    "# Path is TIMIT/<TEST or TRAIN>/<DIALECT>/<SPEAKER ID>/<SEGMENT ID>.wav\n",
    "DATASET_PATH = \"../Timit-Database/TIMIT/\"\n",
    "ALL_WAVS_PATH = os.path.join(DATASET_PATH, \"*\", \"*\", \"*\", \"*.wav\")\n",
    "\n",
    "speech_paths = glob.glob(ALL_WAVS_PATH)\n",
    "print(f\"Importing {len(speech_paths)} speech samples\")\n",
    "\n",
    "speech_paths = AudioProcessing.select_samples(\n",
    "    speech_paths,\n",
    "    num_samples=Constants.EXPERIMENTATION.NUM_SPEECH_SAMPLES\n",
    ")\n",
    "\n",
    "print(f\"Succesfully randomly sampled {len(speech_paths)} speech samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Create the Data Structure for Saving the Hidden States\n",
    "\n",
    "```\n",
    "For Each Phoneme\n",
    "    For Each Encoder \n",
    "        For Each Sequence of 1024 Vectors\n",
    "            Append Hidden State\n",
    "```\n",
    "\n",
    "Hidden States maps <`phoneme string`, a list of`Hidden State Representation`>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_hidden_states = defaultdict(lambda: [np.empty(\n",
    "#     (Constants.LLM.NUM_ENCODERS,\n",
    "#      Constants.LLM.EMBEDDING_SIZE,\n",
    "#      0  # To append a variable size # of speech vectors determined by length of speech input\n",
    "#      ),\n",
    "#     dtype=float\n",
    "# )])\n",
    "all_hidden_states = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Calculate Boundaries for each Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=2, _1=10, _2=14, _3='iy')\n",
      "(25, 4, 1024)\n",
      "Pandas(Index=4, _1=19, _2=27, _3='ao')\n",
      "(25, 8, 1024)\n",
      "Pandas(Index=10, _1=40, _2=47, _3='ae')\n",
      "(25, 7, 1024)\n",
      "Pandas(Index=23, _1=81, _2=88, _3='ow')\n",
      "(25, 7, 1024)\n"
     ]
    }
   ],
   "source": [
    "for path in speech_paths:\n",
    "    # Step 1) Generate the hidden states and boundaries\n",
    "    embedded_audio, num_speech_frames, sequence_length = AudioProcessing.process_audio(\n",
    "        wav_path=path,\n",
    "        embedding_model=Constants.EXPERIMENTATION.EMBEDDING_MODEL,\n",
    "        inference_model=Constants.EXPERIMENTATION.INFERENCE_MODEL,\n",
    "        sampling_rate=16000\n",
    "    )\n",
    "\n",
    "    scaled_segmentation = AudioProcessing.get_sequence_boundary(\n",
    "        TIMIT_wav_path=path,\n",
    "        num_speech_frames=num_speech_frames,\n",
    "        num_speech_vec=sequence_length\n",
    "    )\n",
    "\n",
    "    # Step 2) Select boundaries for matching phonemes\n",
    "    filtered_segmentation = AudioProcessing.filter_segmentation(\n",
    "        combined_df=scaled_segmentation,\n",
    "        desired_phonemes=TenseLax.getSet()\n",
    "    )\n",
    "\n",
    "    # Step 3) Place Hidden State into output matrix\n",
    "    for row in filtered_segmentation.itertuples():\n",
    "        print(row)\n",
    "        _, seq_start_vec_idx, seq_end_vec_idx, phoneme = row\n",
    "        \n",
    "        # Step 3a) Get the Hidden States per encoder for the entire speech segment\n",
    "        utterance_hidden_states = AudioProcessing.get_hidden_states(\n",
    "            input_embedding=embedded_audio,\n",
    "            inference_model=Constants.EXPERIMENTATION.INFERENCE_MODEL,\n",
    "            start_idx=seq_start_vec_idx,\n",
    "            end_idx=seq_end_vec_idx \n",
    "        )\n",
    "\n",
    "        # Step 3b) Append hidden States to the existing hidden states for this row\n",
    "        all_hidden_states[phoneme].append(\n",
    "            utterance_hidden_states\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Save Phoneme Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 4, 1024)\n",
      "(1, 25, 4, 1024)\n"
     ]
    }
   ],
   "source": [
    "for phoneme, hidden_state in all_hidden_states.items():\n",
    "    save_path = os.path.join(Constants.PATHING.hidden_state_save_path, f\"HS_{phoneme}.npy\")\n",
    "    for entry in hidden_state:\n",
    "        print(entry.shape)\n",
    "    combined_per_segment = np.array(hidden_state)\n",
    "    print(combined_per_segment.shape)\n",
    "    break\n",
    "    # np.save(save_path, combined_per_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "(3, 2)\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "# x1 = np.array([\n",
    "#     [1, 2, 3],\n",
    "#     [4, 5, 6]\n",
    "# ])\n",
    "\n",
    "# x2 = np.array([\n",
    "#     [10, 20, 30],\n",
    "#     [40, 50, 60]\n",
    "# ])\n",
    "# print(x1.shape)\n",
    "# print(x2.shape)\n",
    "\n",
    "# print(np.append(x1, x2))\n",
    "# print(np.append(x1, x2, axis=0))\n",
    "# print(np.append(x1, x2, axis=1))\n",
    "\n",
    "x3 = np.array([[1, 2, 3],[4, 5, 6]])\n",
    "print(x3.shape)\n",
    "print(x3)\n",
    "\n",
    "print()\n",
    "print(x3.T.shape)\n",
    "print(x3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample: [  4   3 100]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define an array\n",
    "my_array = np.array([1, 100, 3, 4, 5])\n",
    "\n",
    "# Generate a random sample from the array\n",
    "random_sample = np.random.choice(my_array,3, replace=True)\n",
    "\n",
    "print(\"Random sample:\", random_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  IsStudent\n",
      "0    Alice   25       True\n",
      "2  Charlie   35       True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'IsStudent': [True, False, True, False]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Set of names to filter\n",
    "names_to_filter = {'Alice', 'Charlie'}\n",
    "\n",
    "# Boolean condition: filtering only rows where 'Name' is in the set\n",
    "filtered_df = df[df['Name'].isin(names_to_filter)]\n",
    "\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "Name: 2, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame without headers\n",
    "data = [\n",
    "    ['Alice', 25, True],\n",
    "    ['Bob', 30, False],\n",
    "    ['Charlie', 35, True],\n",
    "    ['David', 40, False]\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extracting the 3rd column (index 2)\n",
    "third_column = df.iloc[:, 2]\n",
    "\n",
    "print(third_column)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
