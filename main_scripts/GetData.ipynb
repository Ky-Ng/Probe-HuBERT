{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting HuBERT Hidden Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleng/B_Organized/A_School/Ling_487/clean_code/Probe-HuBERT/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertForCTC: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForCTC were not initialized from the model checkpoint at facebook/hubert-large-ls960-ft and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Packages\n",
    "import librosa\n",
    "from transformers import HubertForCTC, Wav2Vec2Processor\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Custom Helper Libraries\n",
    "from helper_scripts.TenseLax import TenseLax\n",
    "from helper_scripts.AudioProcessing import AudioProcessing\n",
    "from helper_scripts.Constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roadmap\n",
    "```\n",
    "let n = number of samples of audio files\n",
    "let s = number of segments/phonemes to be segmented\n",
    "let k = number of encoders in LLM\n",
    "let l[i] = number of speech vectors per input sequence\n",
    "```\n",
    "\n",
    "1) Select n=200 samples of audio files from a specific subset of dialects from `TIMIT`\n",
    "2) Create the output `hidden_states`\n",
    "    - s entries\n",
    "    - each entry is a size k=25 array \n",
    "    - each array index is a numpy array representing `l[i]` speech vectors--where each speech vector is of size 1024\n",
    "3) Load in each of the n samples using `librosa`\n",
    "4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import Audio Files\n",
    "- Extract 200 path's to audio samples to save computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iy', 'ih', 'eh', 'ey', 'eh', 'ae', 'ow', 'ao', 'uw', 'uh']\n"
     ]
    }
   ],
   "source": [
    "# DESIRED_PHONEMES = *TenseLax.getPairs()\n",
    "DESIRED_PHONEMES = [vowel for vowel_pair in TenseLax.getPairs() for vowel in vowel_pair]\n",
    "print (DESIRED_PHONEMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 4969 speech samples\n",
      "Succesfully randomly sampled 200 speech samples\n"
     ]
    }
   ],
   "source": [
    "# Path is TIMIT/<TEST or TRAIN>/<DIALECT>/<SPEAKER ID>/<SEGMENT ID>.wav\n",
    "DATASET_PATH = \"../Timit-Database/TIMIT/\"\n",
    "ALL_WAVS_PATH = os.path.join(DATASET_PATH, \"*\", \"*\", \"*\", \"*.wav\")\n",
    "\n",
    "speech_paths = glob.glob(ALL_WAVS_PATH)\n",
    "print(f\"Importing {len(speech_paths)} speech samples\")\n",
    "\n",
    "speech_paths = AudioProcessing.select_samples(\n",
    "    speech_paths,\n",
    "    num_samples=Constants.EXPERIMENTATION.NUM_SPEECH_SAMPLES\n",
    ")\n",
    "\n",
    "print(f\"Succesfully randomly sampled {len(speech_paths)} speech samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Calculate Boundaries for each Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in speech_paths:\n",
    "    embedded_audio, sequence_length = AudioProcessing.process_audio(\n",
    "        wav_path=path,\n",
    "        embedding_model=Constants.EXPERIMENTATION.EMBEDDING_MODEL,\n",
    "        inference_model=Constants.EXPERIMENTATION.INFERENCE_MODEL,\n",
    "        sampling_rate=16000\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "(3, 2)\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "# x1 = np.array([\n",
    "#     [1, 2, 3],\n",
    "#     [4, 5, 6]\n",
    "# ])\n",
    "\n",
    "# x2 = np.array([\n",
    "#     [10, 20, 30],\n",
    "#     [40, 50, 60]\n",
    "# ])\n",
    "# print(x1.shape)\n",
    "# print(x2.shape)\n",
    "\n",
    "# print(np.append(x1, x2))\n",
    "# print(np.append(x1, x2, axis=0))\n",
    "# print(np.append(x1, x2, axis=1))\n",
    "\n",
    "x3 = np.array([[1, 2, 3],[4, 5, 6]])\n",
    "print(x3.shape)\n",
    "print(x3)\n",
    "\n",
    "print()\n",
    "print(x3.T.shape)\n",
    "print(x3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample: [  4   1 100]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define an array\n",
    "my_array = np.array([1, 100, 3, 4, 5])\n",
    "\n",
    "# Generate a random sample from the array\n",
    "random_sample = np.random.choice(my_array,3, replace=True)\n",
    "\n",
    "print(\"Random sample:\", random_sample)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
