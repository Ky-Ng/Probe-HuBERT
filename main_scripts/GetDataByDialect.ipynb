{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data By Dialect\n",
    "- modified version of `GetData.ipynb` to segement by Dialect Region\n",
    "- See that version for a more comments/code descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from transformers import HubertForCTC, Wav2Vec2Processor\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict \n",
    "\n",
    "# Custom Helper Libraries\n",
    "from helper_scripts.TenseLax import TenseLax\n",
    "from helper_scripts.AudioProcessing import AudioProcessing\n",
    "from helper_scripts.Constants import *\n",
    "from helper_scripts.Pathing import Pathing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing 0 speech samples for phoneme for dialect DR7\n",
      "Importing 0 speech samples for phoneme for dialect DR8\n"
     ]
    }
   ],
   "source": [
    "# Path is TIMIT/<TEST or TRAIN>/<DIALECT>/<SPEAKER ID>/<SEGMENT ID>.wav\n",
    "DATASET_PATH = \"../Timit-Database/TIMIT/\"\n",
    "for dialect in range(1, Constants.TIMIT.NUM_DIALECTS+1):\n",
    "    ALL_WAVS_PATH = os.path.join(\n",
    "        DATASET_PATH, \"TEST\", f\"DR{dialect}\", \"*\", \"*.wav\")\n",
    "\n",
    "    speech_paths = glob.glob(ALL_WAVS_PATH)\n",
    "    print(f\"Importing {len(speech_paths)} speech samples for phoneme for dialect DR{dialect}\")\n",
    "\n",
    "    all_hidden_states = defaultdict(list)\n",
    "\n",
    "    for path in speech_paths:\n",
    "        # Step 1) Generate the hidden states and boundaries\n",
    "        embedded_audio, num_speech_frames, sequence_length = AudioProcessing.process_audio(\n",
    "            wav_path=path,\n",
    "            embedding_model=Constants.EXPERIMENTATION.EMBEDDING_MODEL,\n",
    "            inference_model=Constants.EXPERIMENTATION.INFERENCE_MODEL,\n",
    "            sampling_rate=16000\n",
    "        )\n",
    "\n",
    "        scaled_segmentation = AudioProcessing.get_sequence_boundary(\n",
    "            TIMIT_wav_path=path,\n",
    "            num_speech_frames=num_speech_frames,\n",
    "            num_speech_vec=sequence_length\n",
    "        )\n",
    "\n",
    "        # Step 2) Select boundaries for matching phonemes\n",
    "        filtered_segmentation = AudioProcessing.filter_segmentation(\n",
    "            combined_df=scaled_segmentation,\n",
    "            desired_phonemes=TenseLax.getSet()\n",
    "        )\n",
    "\n",
    "        # Step 3) Place Hidden State into output matrix\n",
    "        for row in filtered_segmentation.itertuples():\n",
    "            _, seq_start_vec_idx, seq_end_vec_idx, phoneme = row\n",
    "\n",
    "            # Step 3a) Get the Hidden States per encoder for the entire speech segment\n",
    "            utterance_hidden_states = AudioProcessing.get_hidden_states(\n",
    "                input_embedding=embedded_audio,\n",
    "                inference_model=Constants.EXPERIMENTATION.INFERENCE_MODEL,\n",
    "                start_idx=seq_start_vec_idx,\n",
    "                end_idx=seq_end_vec_idx\n",
    "            )\n",
    "\n",
    "            # Step 3b) Append hidden States to the existing hidden states for this row\n",
    "            all_hidden_states[phoneme].append(\n",
    "                utterance_hidden_states\n",
    "            )\n",
    "\n",
    "    for phoneme, hidden_state in all_hidden_states.items():\n",
    "        combined_per_segment = np.concatenate(hidden_state, axis=1)\n",
    "        Pathing.save_file_np(\n",
    "            save_dir=os.path.join(\n",
    "                Constants.PATHING.hidden_state_save_path, f\"DR{dialect}\"),\n",
    "            save_file_name=f\"HS_{phoneme}_{\n",
    "                combined_per_segment.shape[1]}.npy\",\n",
    "            to_save=combined_per_segment\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
